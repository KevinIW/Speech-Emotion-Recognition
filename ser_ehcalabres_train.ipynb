{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7976ee3b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-12T13:18:56.617481Z",
     "iopub.status.busy": "2025-05-12T13:18:56.617208Z",
     "iopub.status.idle": "2025-05-12T13:18:56.623498Z",
     "shell.execute_reply": "2025-05-12T13:18:56.622837Z",
     "shell.execute_reply.started": "2025-05-12T13:18:56.617461Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import os\n",
    "os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
    "\n",
    "import torch\n",
    "import librosa\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import soundfile as sf\n",
    "from datasets import Features, Value, Sequence, Dataset\n",
    "import evaluate\n",
    "from transformers import (\n",
    "    AutoModelForAudioClassification,\n",
    "    Wav2Vec2FeatureExtractor,\n",
    "    TrainingArguments,\n",
    "    Trainer,\n",
    ")\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Set the device to GPU if available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "41e6dbcf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-12T13:18:56.624907Z",
     "iopub.status.busy": "2025-05-12T13:18:56.624615Z",
     "iopub.status.idle": "2025-05-12T13:18:56.642562Z",
     "shell.execute_reply": "2025-05-12T13:18:56.641907Z",
     "shell.execute_reply.started": "2025-05-12T13:18:56.624891Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Paths\n",
    "dataset_dir = '.'\n",
    "train_csv = os.path.join(dataset_dir, 'train.csv')\n",
    "test_csv = os.path.join(dataset_dir, 'test.csv')\n",
    "train_audio_dir = os.path.join(dataset_dir, 'train')\n",
    "test_audio_dir = os.path.join(dataset_dir, 'test')\n",
    "\n",
    "# Label mapping\n",
    "e_labels = {\"marah\": 0, \"jijik\": 1, \"takut\": 2, \"bahagia\": 3, \"netral\": 4, \"sedih\": 5}\n",
    "\n",
    "# Model checkpoint\n",
    "checkpoint = \"ehcalabres/wav2vec2-lg-xlsr-en-speech-emotion-recognition\"\n",
    "out_dir = \"./wav2vec2-emotion-6\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "703f9fef",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-12T13:18:56.643413Z",
     "iopub.status.busy": "2025-05-12T13:18:56.643187Z",
     "iopub.status.idle": "2025-05-12T13:18:56.735489Z",
     "shell.execute_reply": "2025-05-12T13:18:56.734932Z",
     "shell.execute_reply.started": "2025-05-12T13:18:56.643398Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Load metadata\n",
    "train_df = pd.read_csv(train_csv)\n",
    "test_df = pd.read_csv(test_csv)\n",
    "\n",
    "# Encode labels\n",
    "le = LabelEncoder()\n",
    "le.classes_ = np.array(list(e_labels.keys()))\n",
    "train_df['label'] = train_df['label'].map(e_labels)\n",
    "\n",
    "# Create HuggingFace Datasets\n",
    "ds_train = Dataset.from_pandas(train_df)\n",
    "ds_test = Dataset.from_pandas(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d4eeacb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-12T13:18:56.737382Z",
     "iopub.status.busy": "2025-05-12T13:18:56.737171Z",
     "iopub.status.idle": "2025-05-12T13:18:57.428550Z",
     "shell.execute_reply": "2025-05-12T13:18:57.428025Z",
     "shell.execute_reply.started": "2025-05-12T13:18:56.737366Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at ehcalabres/wav2vec2-lg-xlsr-en-speech-emotion-recognition were not used when initializing Wav2Vec2ForSequenceClassification: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.output.bias', 'classifier.output.weight']\n",
      "- This IS expected if you are initializing Wav2Vec2ForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing Wav2Vec2ForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of Wav2Vec2ForSequenceClassification were not initialized from the model checkpoint at ehcalabres/wav2vec2-lg-xlsr-en-speech-emotion-recognition and are newly initialized: ['classifier.bias', 'classifier.weight', 'projector.bias', 'projector.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "feature_extractor = Wav2Vec2FeatureExtractor.from_pretrained(checkpoint)\n",
    "model = AutoModelForAudioClassification.from_pretrained(\n",
    "    checkpoint,\n",
    "    num_labels=6\n",
    ")\n",
    "model.gradient_checkpointing_enable()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2e4d40e3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-12T13:18:57.429466Z",
     "iopub.status.busy": "2025-05-12T13:18:57.429236Z",
     "iopub.status.idle": "2025-05-12T13:20:03.675409Z",
     "shell.execute_reply": "2025-05-12T13:20:03.674585Z",
     "shell.execute_reply.started": "2025-05-12T13:18:57.429439Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d66041b78b6a4d8c8c87879e6d5f3db5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/6798 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4078e1fce24f4379b1cef3d96a831695",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1700 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def custom_data_collator(features):\n",
    "    # Get input values and find max length\n",
    "    input_values = [feature[\"input_values\"] for feature in features]\n",
    "    max_length = max(len(x) for x in input_values)\n",
    "    \n",
    "    # Pad input values to the same length\n",
    "    padded_inputs = []\n",
    "    attention_masks = []\n",
    "    for inputs in input_values:\n",
    "        # Create padding\n",
    "        padding_length = max_length - len(inputs)\n",
    "        padded_input = np.pad(inputs, (0, padding_length), 'constant', constant_values=0)\n",
    "        # Create attention mask (1 for real values, 0 for padding)\n",
    "        attention_mask = np.concatenate([\n",
    "            np.ones(len(inputs)),\n",
    "            np.zeros(padding_length)\n",
    "        ])\n",
    "        \n",
    "        padded_inputs.append(padded_input)\n",
    "        attention_masks.append(attention_mask)\n",
    "    \n",
    "    # Now create tensors from padded sequences\n",
    "    if \"label\" in features[0].keys():\n",
    "        labels = [feature[\"label\"] for feature in features]\n",
    "        batch = {\n",
    "            \"input_values\": torch.tensor(padded_inputs, dtype=torch.float32),\n",
    "            \"attention_mask\": torch.tensor(attention_masks, dtype=torch.float32),\n",
    "            \"labels\": torch.tensor(labels, dtype=torch.long)\n",
    "        }\n",
    "    else:\n",
    "        batch = {\n",
    "            \"input_values\": torch.tensor(padded_inputs, dtype=torch.float32),\n",
    "            \"attention_mask\": torch.tensor(attention_masks, dtype=torch.float32)\n",
    "        }\n",
    "    \n",
    "    return batch\n",
    "\n",
    "def prepare_batch(batch, audio_dir):\n",
    "    try:\n",
    "        file_path = os.path.join(audio_dir, batch[\"id\"])\n",
    "        if not os.path.exists(file_path) and os.path.exists(file_path + \".wav\"):\n",
    "            file_path = file_path + \".wav\"\n",
    "            \n",
    "        speech, sr = sf.read(file_path)\n",
    "        \n",
    "        if sr != 16000:\n",
    "            speech = librosa.resample(\n",
    "                speech, \n",
    "                orig_sr=sr, \n",
    "                target_sr=16000\n",
    "            )\n",
    "            sr = 16000\n",
    "\n",
    "        if len(speech.shape) > 1:\n",
    "            speech = np.mean(speech, axis=1)\n",
    "        \n",
    "        inputs = feature_extractor(\n",
    "            speech,\n",
    "            sampling_rate=16000,\n",
    "            return_tensors=\"np\",\n",
    "            padding=True\n",
    "        )\n",
    "\n",
    "        return {\n",
    "            \"input_values\": inputs.input_values[0].astype(np.float32),\n",
    "            \"attention_mask\": inputs.attention_mask[0].astype(np.float32) if \"attention_mask\" in inputs else np.ones_like(inputs.input_values[0]).astype(np.float32),\n",
    "            \"label\": np.int64(batch[\"label\"]) if \"label\" in batch else np.int64(0)\n",
    "        }\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {batch['id']}: {e}\")\n",
    "        return {\n",
    "            \"input_values\": np.zeros(16000, dtype=np.float32), \n",
    "            \"attention_mask\": np.ones(16000, dtype=np.float32),\n",
    "            \"label\": np.int64(0)\n",
    "        }\n",
    "\n",
    "features = Features({\n",
    "    'input_values': Sequence(feature=Value(dtype='float32')),\n",
    "    'attention_mask': Sequence(feature=Value(dtype='float32')),\n",
    "    'label': Value(dtype='int64')\n",
    "})\n",
    "\n",
    "ds_train = ds_train.map(\n",
    "    lambda x: prepare_batch(x, train_audio_dir),\n",
    "    remove_columns=ds_train.column_names,\n",
    "    features=features\n",
    ")\n",
    "\n",
    "ds_test = ds_test.map(\n",
    "    lambda x: prepare_batch(x, test_audio_dir),\n",
    "    remove_columns=ds_test.column_names,\n",
    "    features=features\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5af10fb6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-12T15:23:13.327537Z",
     "iopub.status.busy": "2025-05-12T15:23:13.326841Z",
     "iopub.status.idle": "2025-05-12T15:23:14.818742Z",
     "shell.execute_reply": "2025-05-12T15:23:14.817987Z",
     "shell.execute_reply.started": "2025-05-12T15:23:13.327513Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "metric = evaluate.load(\"accuracy\")\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    preds = np.argmax(logits, axis=-1)\n",
    "    return metric.compute(predictions=preds, references=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "90921886",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-12T13:20:05.191301Z",
     "iopub.status.busy": "2025-05-12T13:20:05.191056Z",
     "iopub.status.idle": "2025-05-12T13:20:05.222334Z",
     "shell.execute_reply": "2025-05-12T13:20:05.221805Z",
     "shell.execute_reply.started": "2025-05-12T13:20:05.191274Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "args = TrainingArguments(\n",
    "    output_dir=out_dir,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    eval_steps=100,\n",
    "    do_eval=True,\n",
    "    num_train_epochs=6,\n",
    "    save_steps=500,\n",
    "    save_total_limit=2,\n",
    "    logging_dir='./logs',\n",
    "    logging_steps=100,\n",
    "    report_to=[]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77ac6a8e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-12T13:20:05.223300Z",
     "iopub.status.busy": "2025-05-12T13:20:05.223088Z",
     "iopub.status.idle": "2025-05-12T13:20:05.671916Z",
     "shell.execute_reply": "2025-05-12T13:20:05.671158Z",
     "shell.execute_reply.started": "2025-05-12T13:20:05.223282Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=args,\n",
    "    train_dataset=ds_train,\n",
    "    eval_dataset=ds_train,\n",
    "    tokenizer=feature_extractor,\n",
    "    data_collator=custom_data_collator,\n",
    "    compute_metrics=compute_metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "651f39e5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-12T13:20:05.672826Z",
     "iopub.status.busy": "2025-05-12T13:20:05.672625Z",
     "iopub.status.idle": "2025-05-12T15:10:07.327455Z",
     "shell.execute_reply": "2025-05-12T15:10:07.326717Z",
     "shell.execute_reply.started": "2025-05-12T13:20:05.672811Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='5100' max='5100' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [5100/5100 1:49:59, Epoch 6/6]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1.371800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>1.067600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.953300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.937200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.984100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.887800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>0.841700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.870200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.735600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.626300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>0.691900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.632400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1300</td>\n",
       "      <td>0.691500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>0.582800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.677600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>0.561000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1700</td>\n",
       "      <td>0.642600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>0.489500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1900</td>\n",
       "      <td>0.550000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.479100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2100</td>\n",
       "      <td>0.500200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2200</td>\n",
       "      <td>0.478300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2300</td>\n",
       "      <td>0.521500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2400</td>\n",
       "      <td>0.450000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.474900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2600</td>\n",
       "      <td>0.367200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2700</td>\n",
       "      <td>0.341000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2800</td>\n",
       "      <td>0.347700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2900</td>\n",
       "      <td>0.415900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.383400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3100</td>\n",
       "      <td>0.346700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3200</td>\n",
       "      <td>0.419900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3300</td>\n",
       "      <td>0.371100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3400</td>\n",
       "      <td>0.357800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3500</td>\n",
       "      <td>0.294200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3600</td>\n",
       "      <td>0.280900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3700</td>\n",
       "      <td>0.261600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3800</td>\n",
       "      <td>0.254800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3900</td>\n",
       "      <td>0.315700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.290400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4100</td>\n",
       "      <td>0.291400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4200</td>\n",
       "      <td>0.288400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4300</td>\n",
       "      <td>0.313900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4400</td>\n",
       "      <td>0.214700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4500</td>\n",
       "      <td>0.229000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4600</td>\n",
       "      <td>0.168100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4700</td>\n",
       "      <td>0.216400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4800</td>\n",
       "      <td>0.162500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4900</td>\n",
       "      <td>0.230600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>0.263000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5100</td>\n",
       "      <td>0.209100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=5100, training_loss=0.49674665189256856, metrics={'train_runtime': 6601.0289, 'train_samples_per_second': 6.179, 'train_steps_per_second': 0.773, 'total_flos': 4.572850895162956e+18, 'train_loss': 0.49674665189256856, 'epoch': 6.0})"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "8efa4a9a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-12T15:23:24.079026Z",
     "iopub.status.busy": "2025-05-12T15:23:24.078488Z",
     "iopub.status.idle": "2025-05-12T15:25:36.278195Z",
     "shell.execute_reply": "2025-05-12T15:25:36.277435Z",
     "shell.execute_reply.started": "2025-05-12T15:23:24.079002Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved submission.csv\n"
     ]
    }
   ],
   "source": [
    "preds_output = trainer.predict(ds_test)\n",
    "preds = np.argmax(preds_output.predictions, axis=-1)\n",
    "\n",
    "# Map back to labels\n",
    "inv_map = {v: k for k, v in e_labels.items()}\n",
    "pred_labels = [inv_map[p] for p in preds]\n",
    "\n",
    "# Prepare submission\n",
    "submission = pd.DataFrame({'id': test_df['id'], 'label': pred_labels})\n",
    "submission.to_csv('submission.csv', index=False)\n",
    "print(\"Saved submission.csv\")\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 7389868,
     "sourceId": 11779268,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31011,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "ml-lab",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
